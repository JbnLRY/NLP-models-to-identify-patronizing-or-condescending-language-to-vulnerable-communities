We developped a binary classification model to predict whether a text contains patronising or condescending language (PCL). 
We describe our analysis of the training data, and our improvements to the task’s baseline mode (RoBERTa) as well as including analysis of
our model based on attributes of the training data. The Don’t Patronize Me dataset was introduced by Perez-Almendros et al. and is aimed at 
supporting development of NLP models to identify language as patronising or condescending to vulnerable communities. 

The link to our Colab notebook :
https://colab.research.google.com/drive/1n0wu6HHHVScxN9Rm4NFJ-VraJCBtK3x3?usp=sharing
